{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Party ID classification \n",
    "\n",
    "Vivek Datta initially wrote this notebook. Jae Yeon Kim reviwed the notebook, edited the markdown, and reproduced, commented on and made substantial changes in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install uninstalled libs \n",
    "import sys\n",
    "#!conda install --yes --prefix {sys.prefix} textblob\n",
    "\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# NLTK\n",
    "import re\n",
    "import urllib\n",
    "from textblob import TextBlob\n",
    "from gensim.models import Word2Vec\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "import nltk as nlp\n",
    "# nltk.download('punkt') You may need to download the dataset\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.text import Text  \n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# ML\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB # Naive-Bayes\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression # Linear models\n",
    "from xgboost import XGBClassifier # Xgboost\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "################### Validation ######################\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut, LeavePOut, ShuffleSplit, StratifiedKFold\n",
    "\n",
    "################### Vectorizer ######################\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "################### Model evals #####################\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score \n",
    "\n",
    "################### Imbalanced data #####################\n",
    "from sklearn.utils import resample # for resampling\n",
    "\n",
    "# Custom functions\n",
    "from clean_text import clean_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beats by Dr. Dre urBeats Wired In-Ear Headphon...</td>\n",
       "      <td>spam</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Papapishu: Man it would fucking rule if we...</td>\n",
       "      <td>abusive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is time to draw close to Him &amp;#128591;&amp;#127...</td>\n",
       "      <td>normal</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you notice me start to act different or dis...</td>\n",
       "      <td>normal</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forget unfollowers, I believe in growing. 7 ne...</td>\n",
       "      <td>normal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet    label  votes\n",
       "0  Beats by Dr. Dre urBeats Wired In-Ear Headphon...     spam      4\n",
       "1  RT @Papapishu: Man it would fucking rule if we...  abusive      4\n",
       "2  It is time to draw close to Him &#128591;&#127...   normal      4\n",
       "3  if you notice me start to act different or dis...   normal      5\n",
       "4  Forget unfollowers, I believe in growing. 7 ne...   normal      3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('/home/jae/intersectional-bias-in-ml/raw_data/hatespeech_text_label_vote_RESTRICTED_100K.csv', sep='\\t', header=None)\n",
    "\n",
    "# Name columns \n",
    "data.columns = ['Tweet', 'label', 'votes']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beats by dr dre urbeats wired inear headphones...</td>\n",
       "      <td>spam</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>man it would fucking rule if we had a party ...</td>\n",
       "      <td>abusive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is time to draw close to him 128591127995 f...</td>\n",
       "      <td>normal</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you notice me start to act different or dis...</td>\n",
       "      <td>normal</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forget unfollowers i believe in growing 7 new ...</td>\n",
       "      <td>normal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet    label  votes\n",
       "0  beats by dr dre urbeats wired inear headphones...     spam      4\n",
       "1    man it would fucking rule if we had a party ...  abusive      4\n",
       "2  it is time to draw close to him 128591127995 f...   normal      4\n",
       "3  if you notice me start to act different or dis...   normal      5\n",
       "4  forget unfollowers i believe in growing 7 new ...   normal      3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tweet'] = clean_tweet(data['Tweet'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and wrangle training data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vivek Datta adapted the code from [the following Jupyter notebook](https://github.com/chouhbik/Sentiment-Analysis-of-Tweets/blob/master/Tweets%20Analysis%20DemvsRep.ipynb). The original dataset comes from the [Kaggle website](https://www.kaggle.com/kapastor/democratvsrepublicantweets). Jae Yeon Kim made some changes in Vivek's code (mostly on training and evaluating algorithms). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "model_data = pd.read_csv(\"/home/jae/intersectional-bias-in-ml/raw_data/ExtractedTweets.csv\")\n",
    "\n",
    "model_data.dropna(axis = 0, inplace = True)\n",
    "\n",
    "model_data[\"Party_log\"] = [1 if each == \"Democrat\" else 0 for each in model_data.Party]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom list of stopwords \n",
    "\n",
    "STOPWORDS.add(\"rt\")\n",
    "STOPWORDS.add(\"s\")\n",
    "STOPWORDS.add(\"u\")\n",
    "STOPWORDS.add(\"amp\")\n",
    "STOPWORDS.add(\"th\")\n",
    "STOPWORDS.add(\"will\")\n",
    "STOPWORDS.add(\"t\")\n",
    "STOPWORDS.add(\"m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Party ID values \n",
    "\n",
    "democrat=model_data[model_data.Party==\"Democrat\"]\n",
    "republican=model_data[model_data.Party==\"Republican\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean values\n",
    "\n",
    "## Democrats \n",
    "\n",
    "democrat_list=[]\n",
    "for d in democrat.Tweet:\n",
    "    d=re.sub(r'http\\S+', '', d) #remove links\n",
    "    d=re.sub(\"[^a-zA-Z]\", \" \", d) #remove all characters except letters\n",
    "    d=d.lower() #convert all words to lowercase\n",
    "    d=nlp.word_tokenize(d) #split sentences into word\n",
    "    d=[word for word in d if not word in STOPWORDS] #remove the stopwords\n",
    "    lemma=nlp.WordNetLemmatizer() \n",
    "    d=[lemma.lemmatize(word) for word in d] #identify the correct form of the word in the dictionary\n",
    "    d=\" \".join(d)\n",
    "    democrat_list.append(d) #append words to list\n",
    "\n",
    "## Republicans \n",
    "\n",
    "republican_list=[]\n",
    "for r in republican.Tweet:\n",
    "    r=re.sub(r'http\\S+', '', r)\n",
    "    r=re.sub(\"[^a-zA-Z]\", \" \", r)\n",
    "    r=r.lower()\n",
    "    r=nlp.word_tokenize(r)\n",
    "    r=[word for word in r if not word in STOPWORDS]\n",
    "    lemma=nlp.WordNetLemmatizer()\n",
    "    r=[lemma.lemmatize(word) for word in r]\n",
    "    r=\" \".join(r)\n",
    "    republican_list.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 = Republicans, 1 = Democrats. Note that the class size is balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    44392\n",
       "1    42068\n",
       "Name: Party_log, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data['Party_log'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Republican    44392\n",
       "Democrat      42068\n",
       "Name: Party, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data['Party'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction (bag-of-words model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = LancasterStemmer()\n",
    "\n",
    "def token(text):\n",
    "    txt = nlp.word_tokenize(text.lower())\n",
    "    return [st.stem(word) for word in txt]\n",
    "\n",
    "\n",
    "# Vectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features = 4000, # 4,000 is large enough\n",
    "                             min_df = 1, # minimum frequency 1\n",
    "                             ngram_range = (1,2), # ngram \n",
    "                             tokenizer = token,\n",
    "                             analyzer=u'word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn text into document-term matrix\n",
    "\n",
    "def dtm_train(data, condition):\n",
    "    \n",
    "    ############################### DOCUMENT-TERM MATRIX ################################\n",
    "    \n",
    "    # BOW model \n",
    "    \n",
    "    features = vectorizer.fit_transform(data['Tweet']).todense() # Turn into a sparse matrix    \n",
    "\n",
    "    # Response variable\n",
    "    \n",
    "    response = data[condition].values # values \n",
    "\n",
    "    ############################### STRATIFIED RANDOM SAMPLING ################################\n",
    "    \n",
    "    # Split into training and testing sets \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, response, \n",
    "                                                        test_size = 0.2, # training = 80%, test = 20%\n",
    "                                                        random_state = 1234) \n",
    "    \n",
    "    return(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function \n",
    "\n",
    "model_dtm = dtm_train(model_data, 'Party_log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Functions for various ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "\n",
    "def fit_logistic_regression(X_train, y_train):\n",
    "    model = LogisticRegression(penalty = 'l1', # Lasso \n",
    "                               solver = 'liblinear') # for small datasets\n",
    "    # sage solver is faster but doesn't coverge in this case\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Naive-Bayes \n",
    "\n",
    "def fit_bayes(X_train, y_train):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Xgboost\n",
    "\n",
    "def fit_xgboost(X_train, y_train):\n",
    "    model = XGBClassifier(random_state = 42,\n",
    "                         seed = 2, \n",
    "                         colsample_bytree = 0.6,\n",
    "                         subsample = 0.7)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for evaluating ML models (accuracy and balanced accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_train, y_train, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "#   print(\"Accuracy:\", accuracy, \"\\n\"\n",
    "#          \"Balanced accuracy:\", balanced_accuracy)\n",
    "    return(accuracy, balanced_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_models(data):\n",
    "    # Logit\n",
    "    lasso = fit_logistic_regression(data[0], data[1])\n",
    "    # Naive-Bayes\n",
    "    bayes = fit_bayes(data[0], data[1])\n",
    "    # Xgboost\n",
    "    xgboost = fit_xgboost(data[0], data[1])\n",
    "    \n",
    "    return(lasso, bayes, xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = fit_models(model_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model object \n",
    "\n",
    "pickle.dump(model_fit, open('/home/jae/intersectional-bias-in-ml/processed_data/model_fit.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model object \n",
    "\n",
    "model_fit = pickle.load(open('/home/jae/intersectional-bias-in-ml/processed_data/model_fit.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for testing multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(models, data):\n",
    "    lasso = test_model(models[0], data[0], data[1], data[2], data[3]) \n",
    "    bayes = test_model(models[1], data[0], data[1], data[2], data[3])\n",
    "    xgboost = test_model(models[2], data[0], data[1], data[2], data[3])\n",
    "    return(lasso, bayes, xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate multiple models for each data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = test_models(model_fit, model_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for putting the model evaluations into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_table(data):\n",
    "    table = pd.DataFrame(list(data), columns= ['Accuracy','Balanced Accuracy'])\n",
    "    table.insert(loc = 0, column = 'Models', value = ['Lasso', 'Bayes', 'XGBoost'])\n",
    "    return(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.726347</td>\n",
       "      <td>0.725896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.707842</td>\n",
       "      <td>0.706522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.704430</td>\n",
       "      <td>0.703564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Models  Accuracy  Balanced Accuracy\n",
       "0    Lasso  0.726347           0.725896\n",
       "1    Bayes  0.707842           0.706522\n",
       "2  XGBoost  0.704430           0.703564"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "eval_table(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for predicting the unlabeled data (tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text, model):   \n",
    "      \n",
    "    # BOW model \n",
    "    \n",
    "    features = vectorizer.fit_transform(text).todense()\n",
    "    \n",
    "    # Prediction\n",
    "    \n",
    "    preds = model.predict(features)\n",
    "    \n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the function to the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predict_text(data['Tweet'], model_fit[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tweet'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['party_ID'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['party_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the predicted values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"/home/jae/intersectional-bias-in-ml/processed_data/party_ID_predictions.csv\", sep=',', encoding='utf-8', \n",
    "                    header=[\"text\", \"label\", \"votes\", \"party_ID\"], index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
